{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0,Testing Accuracy0.8253\n",
      "Iter1,Testing Accuracy0.8842\n",
      "Iter2,Testing Accuracy0.9005\n",
      "Iter3,Testing Accuracy0.9054\n",
      "Iter4,Testing Accuracy0.9075\n",
      "Iter5,Testing Accuracy0.9096\n",
      "Iter6,Testing Accuracy0.9116\n",
      "Iter7,Testing Accuracy0.914\n",
      "Iter8,Testing Accuracy0.9145\n",
      "Iter9,Testing Accuracy0.916\n",
      "Iter10,Testing Accuracy0.9163\n",
      "Iter11,Testing Accuracy0.9188\n",
      "Iter12,Testing Accuracy0.92\n",
      "Iter13,Testing Accuracy0.9198\n",
      "Iter14,Testing Accuracy0.9195\n",
      "Iter15,Testing Accuracy0.9207\n",
      "Iter16,Testing Accuracy0.9206\n",
      "Iter17,Testing Accuracy0.9206\n",
      "Iter18,Testing Accuracy0.9217\n",
      "Iter19,Testing Accuracy0.921\n",
      "Iter20,Testing Accuracy0.9217\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist=input_data.read_data_sets(\"MNIST_data\",one_hot=True)    #我们要将mnist的0-9的标签转化为“one-hot vectors”。具体见课件\n",
    "\n",
    "#每个批次的大小100\n",
    "batch_size=100                      #以矩阵形式放入100张照片进行训练\n",
    "n_batch=mnist.train.num_examples//batch_size     #数据集训练数量整除批次大小，就是一共需要训练多少个批次\n",
    "\n",
    "#定义两个placeholder\n",
    "x=tf.placeholder(tf.float32,[None,784])                  #28*28=784\n",
    "y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "W=tf.Variable(tf.zeros([784,10]))\n",
    "b=tf.Variable(tf.zeros([1,10]))\n",
    "prediction=tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "#定义二次代价函数\n",
    "# loss=tf.reduce_mean(tf.square(y-prediction))\n",
    "#跟softmax搭配使用的交叉熵代价函数\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "#使用梯度下降法\n",
    "train_step=tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "#argmax返回一维张量中最大的值所在的位置\n",
    "#tf.argmax(prediction,1) 求prediction最大的位置，并返回这个位置的标签，这里1是数字1。本例中判定概率最大的图片属于哪个标签，并返回标签\n",
    "#argmax(y,l) 本例中y的值为0或1，哪个位置是1就会返回这个位置。(0 0 1 0) 1在第二个标签位置上，就会返回2.\n",
    "#本例比较判断出来(predictino)的标签，与真实的标签是否一样，一样的话，就返回True,并存放在correct_prediction里，否则返回False\n",
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1)) #tf.equal()比较两个变量是否相同，相同的返回True，不同返回False\n",
    "\n",
    "#求准确率\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))    #cast()函数是转换类型，这里将布尔型转换为浮点型。true--1.0; false--0.0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):                                     #将下面的循环训练21次，就是将所有的图片训练21次\n",
    "        for batch in range(n_batch):                            #该循环将所有批次的图片拿来训练一次，按批次循环，每批次100张图片\n",
    "            batch_xs,batch_ys=mnist.train.next_batch(batch_size)#获得一个批次数量的图片（100个），图片数据保存在batch_xs，图片标签存在batch_ys\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "        acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})            #喂进去测试集的图片和标签\n",
    "        print('Iter'+str(epoch)+',Testing Accuracy'+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 二次代价函数\n",
    "Iter0,Testing Accuracy0.8295\n",
    "Iter1,Testing Accuracy0.8712\n",
    "Iter2,Testing Accuracy0.8817\n",
    "Iter3,Testing Accuracy0.8884\n",
    "Iter4,Testing Accuracy0.8942\n",
    "Iter5,Testing Accuracy0.8971\n",
    "Iter6,Testing Accuracy0.8989\n",
    "Iter7,Testing Accuracy0.9025\n",
    "Iter8,Testing Accuracy0.9034\n",
    "Iter9,Testing Accuracy0.9054\n",
    "Iter10,Testing Accuracy0.9058\n",
    "Iter11,Testing Accuracy0.9074\n",
    "Iter12,Testing Accuracy0.9087\n",
    "Iter13,Testing Accuracy0.9094\n",
    "Iter14,Testing Accuracy0.9098\n",
    "Iter15,Testing Accuracy0.9114\n",
    "Iter16,Testing Accuracy0.9119\n",
    "Iter17,Testing Accuracy0.9121\n",
    "Iter18,Testing Accuracy0.9124\n",
    "Iter19,Testing Accuracy0.9137\n",
    "Iter20,Testing Accuracy0.914\n",
    "#跟softmax搭配使用的交叉熵代价函数\n",
    "Iter0,Testing Accuracy0.8373\n",
    "Iter1,Testing Accuracy0.8946\n",
    "Iter2,Testing Accuracy0.9032\n",
    "Iter3,Testing Accuracy0.9063\n",
    "Iter4,Testing Accuracy0.9083\n",
    "Iter5,Testing Accuracy0.9096\n",
    "Iter6,Testing Accuracy0.9122\n",
    "Iter7,Testing Accuracy0.9138\n",
    "Iter8,Testing Accuracy0.9151\n",
    "Iter9,Testing Accuracy0.9167\n",
    "Iter10,Testing Accuracy0.9173\n",
    "Iter11,Testing Accuracy0.9178\n",
    "Iter12,Testing Accuracy0.92\n",
    "Iter13,Testing Accuracy0.9202\n",
    "Iter14,Testing Accuracy0.9208\n",
    "Iter15,Testing Accuracy0.9209\n",
    "Iter16,Testing Accuracy0.9203\n",
    "Iter17,Testing Accuracy0.9209\n",
    "Iter18,Testing Accuracy0.9207\n",
    "Iter19,Testing Accuracy0.922\n",
    "Iter20,Testing Accuracy0.9214"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
